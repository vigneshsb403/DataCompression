{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lossy-VAE Demo for Google Colab & Kaggle\n",
        "\n",
        "This notebook demonstrates how to use the Lossy-VAE project for image compression on Google Colab or Kaggle.\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "**For Google Colab:**\n",
        "1. Upload the `DataCompression` folder to `/content/`\n",
        "2. Make sure GPU is enabled (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
        "\n",
        "**For Kaggle:**\n",
        "1. Upload the `DataCompression` folder as a dataset\n",
        "2. Make sure GPU accelerator is selected\n",
        "3. Update the dataset path in the setup cell below\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "def detect_platform():\n",
        "    if 'COLAB_GPU' in os.environ:\n",
        "        return 'colab'\n",
        "    elif 'KAGGLE_KERNEL_TYPE' in os.environ:\n",
        "        return 'kaggle'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "platform = detect_platform()\n",
        "print(f\"Platform detected: {platform}\")\n",
        "\n",
        "if platform == 'colab':\n",
        "    project_dir = Path('/content/DataCompression/lossy-vae')\n",
        "    datasets_root = Path('/content/datasets')\n",
        "elif platform == 'kaggle':\n",
        "    project_dir = Path('/kaggle/working/DataCompression/lossy-vae')\n",
        "    datasets_root = Path('/kaggle/input/datasets')\n",
        "    # If you uploaded as a dataset, copy it to working directory\n",
        "    if not project_dir.exists():\n",
        "        import shutil\n",
        "        input_path = Path('/kaggle/input')\n",
        "        # Find the dataset folder (you may need to adjust this)\n",
        "        for item in input_path.iterdir():\n",
        "            if 'datacompression' in item.name.lower():\n",
        "                shutil.copytree(item / 'DataCompression', \n",
        "                              '/kaggle/working/DataCompression', \n",
        "                              dirs_exist_ok=True)\n",
        "                break\n",
        "else:\n",
        "    project_dir = Path('.')\n",
        "    datasets_root = Path('./datasets')\n",
        "\n",
        "print(f\"Project directory: {project_dir}\")\n",
        "print(f\"Datasets directory: {datasets_root}\")\n",
        "\n",
        "if not project_dir.exists():\n",
        "    print(f\"ERROR: Project directory not found at {project_dir}\")\n",
        "    print(\"Please upload the project files first!\")\n",
        "else:\n",
        "    os.chdir(project_dir)\n",
        "    print(f\"Changed to directory: {os.getcwd()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "print(\"Fixing numpy compatibility issue...\")\n",
        "print(\"Installing compatible numpy version (1.26.4)...\")\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', '--force-reinstall', 'numpy==1.26.4'], check=False)\n",
        "\n",
        "dependencies = ['tqdm', 'timm', 'compressai']\n",
        "\n",
        "print(\"\\nInstalling dependencies...\")\n",
        "for dep in dependencies:\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', dep], check=False)\n",
        "\n",
        "print(\"\\nChecking PyTorch...\")\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "print(\"\\nVerifying numpy version...\")\n",
        "import numpy as np\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "\n",
        "print(\"\\nInstalling project...\")\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', '-e', '.'], check=False)\n",
        "\n",
        "print(\"\\n‚úÖ Setup complete!\")\n",
        "print(\"\\n‚ö†Ô∏è  IMPORTANT: Restart runtime now (Runtime ‚Üí Restart runtime)\")\n",
        "print(\"   Then run the next cell to load the model.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è RESTART RUNTIME NOW!\n",
        "\n",
        "**After running the setup cell above, you MUST restart the runtime:**\n",
        "\n",
        "- **Colab**: `Runtime` ‚Üí `Restart runtime`\n",
        "- **Kaggle**: `Session` ‚Üí `Restart Session`\n",
        "\n",
        "This is required for numpy version changes to take effect.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Pre-trained Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# Check if numpy version is compatible\n",
        "if int(np.__version__.split('.')[0]) >= 2:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: NumPy 2.x detected! This will cause compatibility issues.\")\n",
        "    print(\"\\nüîß Fix steps:\")\n",
        "    print(\"1. Run this in a new cell:\")\n",
        "    print(\"   !pip install --force-reinstall numpy==1.26.4\")\n",
        "    print(\"2. Restart runtime: Runtime ‚Üí Restart runtime\")\n",
        "    print(\"3. Run this cell again\")\n",
        "    raise ValueError(\"NumPy 2.x is incompatible. Please install numpy 1.26.4 and restart runtime.\")\n",
        "\n",
        "print(\"‚úÖ NumPy version looks compatible\")\n",
        "\n",
        "try:\n",
        "    # Import models to register them\n",
        "    from lvae.models import qarv, qresvae, rd\n",
        "    from lvae import get_model\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"\\nUsing device: {device}\")\n",
        "    \n",
        "    model_name = 'qarv_base'\n",
        "    print(f\"Loading model: {model_name}\")\n",
        "    \n",
        "    model = get_model(model_name, pretrained=True)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    model.compress_mode(True)\n",
        "    \n",
        "    print(\"‚úÖ Model loaded successfully!\")\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "except ValueError as e:\n",
        "    if \"numpy.dtype size changed\" in str(e):\n",
        "        print(\"\\n‚ùå NumPy compatibility issue detected!\")\n",
        "        print(\"\\nüîß Fix steps:\")\n",
        "        print(\"1. Run this command in a new cell:\")\n",
        "        print(\"   !pip install --force-reinstall numpy==1.26.4\")\n",
        "        print(\"2. Restart runtime: Runtime ‚Üí Restart runtime\")\n",
        "        print(\"3. Run this cell again\")\n",
        "        raise\n",
        "    else:\n",
        "        raise\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")\n",
        "    if \"numpy\" in str(e).lower():\n",
        "        print(\"\\nüîß If this is a numpy error, try:\")\n",
        "        print(\"1. !pip install --force-reinstall numpy==1.26.4\")\n",
        "        print(\"2. Restart runtime\")\n",
        "        print(\"3. Run this cell again\")\n",
        "    raise\n",
        "    else:\n",
        "        raise\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Compress and Decompress an Image\n",
        "\n",
        "Let's compress an image and then decompress it to see the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms.functional as tvf\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if platform == 'colab':\n",
        "    from google.colab import files\n",
        "    from IPython.display import display, Image as IPImage\n",
        "\n",
        "test_image_path = project_dir / 'images' / 'collie128.png'\n",
        "\n",
        "if not test_image_path.exists():\n",
        "    print(f\"Test image not found at {test_image_path}\")\n",
        "    print(\"Please upload an image or use a different path\")\n",
        "else:\n",
        "    print(f\"Loading image from: {test_image_path}\")\n",
        "    \n",
        "    img = Image.open(test_image_path)\n",
        "    print(f\"Image size: {img.size}\")\n",
        "    \n",
        "    compressed_path = '/tmp/compressed.bits'\n",
        "    \n",
        "    model.compress_file(str(test_image_path), compressed_path)\n",
        "    \n",
        "    file_size = Path(compressed_path).stat().st_size\n",
        "    original_size = test_image_path.stat().st_size\n",
        "    compression_ratio = original_size / file_size\n",
        "    \n",
        "    print(f\"\\nCompression stats:\")\n",
        "    print(f\"Original size: {original_size:,} bytes\")\n",
        "    print(f\"Compressed size: {file_size:,} bytes\")\n",
        "    print(f\"Compression ratio: {compression_ratio:.2f}x\")\n",
        "    \n",
        "    reconstructed = model.decompress_file(compressed_path)\n",
        "    \n",
        "    save_path = '/tmp/reconstructed.png'\n",
        "    save_image(reconstructed, save_path)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    recon_img = Image.open(save_path)\n",
        "    axes[1].imshow(recon_img)\n",
        "    axes[1].set_title('Reconstructed Image')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nReconstructed image saved to: {save_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Variable Rate Compression\n",
        "\n",
        "The QARV model supports variable rate compression. Let's try different compression rates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "if test_image_path.exists():\n",
        "    lambdas = [16, 64, 256, 1024]\n",
        "    \n",
        "    fig, axes = plt.subplots(1, len(lambdas) + 1, figsize=(16, 4))\n",
        "    \n",
        "    original_img = Image.open(test_image_path)\n",
        "    axes[0].imshow(original_img)\n",
        "    axes[0].set_title('Original')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    for idx, lmb in enumerate(lambdas):\n",
        "        compressed_path = f'/tmp/compressed_lmb{lmb}.bits'\n",
        "        \n",
        "        model.compress_file(str(test_image_path), compressed_path, lmb=lmb)\n",
        "        reconstructed = model.decompress_file(compressed_path)\n",
        "        \n",
        "        save_path = f'/tmp/reconstructed_lmb{lmb}.png'\n",
        "        save_image(reconstructed, save_path)\n",
        "        \n",
        "        recon_img = Image.open(save_path)\n",
        "        axes[idx + 1].imshow(recon_img)\n",
        "        \n",
        "        file_size = Path(compressed_path).stat().st_size\n",
        "        bpp = (file_size * 8) / (original_img.height * original_img.width)\n",
        "        \n",
        "        axes[idx + 1].set_title(f'Œª={lmb}\\nBPP={bpp:.3f}')\n",
        "        axes[idx + 1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Variable rate compression complete!\")\n",
        "    print(\"Lower Œª = lower quality, smaller file size\")\n",
        "    print(\"Higher Œª = higher quality, larger file size\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Download and Evaluate on Kodak Dataset\n",
        "\n",
        "Let's download the Kodak test dataset and evaluate the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from torch.hub import download_url_to_file\n",
        "from tqdm import tqdm\n",
        "\n",
        "def download_kodak_dataset(target_dir):\n",
        "    target_dir = Path(target_dir)\n",
        "    target_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    print(f\"Downloading Kodak dataset to {target_dir}...\")\n",
        "    urls = [f'http://r0k.us/graphics/kodak/kodak/kodim{str(a).zfill(2)}.png' for a in range(1, 25)]\n",
        "    \n",
        "    for url in tqdm(urls):\n",
        "        filename = Path(url).name\n",
        "        filepath = target_dir / filename\n",
        "        if not filepath.exists():\n",
        "            download_url_to_file(url, str(filepath), progress=False)\n",
        "    \n",
        "    print(f\"Downloaded {len(list(target_dir.glob('*.png')))} images\")\n",
        "    return target_dir\n",
        "\n",
        "kodak_dir = datasets_root / 'kodak'\n",
        "kodak_dir = download_kodak_dataset(kodak_dir)\n",
        "\n",
        "from lvae.paths import known_datasets\n",
        "known_datasets['kodak'] = str(kodak_dir)\n",
        "print(f\"\\nKodak dataset path set to: {kodak_dir}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 4: Quick Evaluation\n",
        "\n",
        "Run a quick evaluation on a few images from the Kodak dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lvae.evaluation import imcoding_evaluate\n",
        "import math\n",
        "\n",
        "if kodak_dir.exists():\n",
        "    print(\"Running evaluation on Kodak dataset...\")\n",
        "    print(\"This may take a few minutes...\\n\")\n",
        "    \n",
        "    results = imcoding_evaluate(model, 'kodak')\n",
        "    \n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(f\"Average BPP: {results['bpp']:.4f}\")\n",
        "    print(f\"Average PSNR: {results['psnr']:.2f} dB\")\n",
        "    print(f\"Average MSE: {results['mse']:.6f}\")\n",
        "    \n",
        "    if 'ssim' in results:\n",
        "        print(f\"Average SSIM: {results['ssim']:.4f}\")\n",
        "else:\n",
        "    print(\"Kodak dataset not found. Skipping evaluation.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 5: Upload Your Own Image\n",
        "\n",
        "Upload and compress your own image!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if platform == 'colab':\n",
        "    from google.colab import files\n",
        "    from IPython.display import display\n",
        "    \n",
        "    print(\"Upload an image to compress:\")\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"\\nProcessing {filename}...\")\n",
        "        \n",
        "        compressed_path = f'/tmp/{Path(filename).stem}_compressed.bits'\n",
        "        model.compress_file(filename, compressed_path)\n",
        "        \n",
        "        file_size = Path(compressed_path).stat().st_size\n",
        "        original_size = Path(filename).stat().st_size\n",
        "        compression_ratio = original_size / file_size\n",
        "        \n",
        "        print(f\"Original: {original_size:,} bytes\")\n",
        "        print(f\"Compressed: {file_size:,} bytes\")\n",
        "        print(f\"Ratio: {compression_ratio:.2f}x\")\n",
        "        \n",
        "        reconstructed = model.decompress_file(compressed_path)\n",
        "        save_path = f'/tmp/{Path(filename).stem}_reconstructed.png'\n",
        "        save_image(reconstructed, save_path)\n",
        "        \n",
        "        print(f\"\\nReconstructed image saved to: {save_path}\")\n",
        "        display(IPImage(save_path))\n",
        "        \n",
        "        files.download(save_path)\n",
        "else:\n",
        "    print(\"For Kaggle, please add your image to the input folder or use the file browser.\")\n",
        "    print(\"Then update the path below:\")\n",
        "    # custom_image_path = '/kaggle/input/your-image.png'\n",
        "    # model.compress_file(custom_image_path, '/tmp/compressed.bits')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "You've learned how to:\n",
        "1. ‚úÖ Set up the Lossy-VAE project on Colab/Kaggle\n",
        "2. ‚úÖ Load pre-trained models\n",
        "3. ‚úÖ Compress and decompress images\n",
        "4. ‚úÖ Use variable rate compression\n",
        "5. ‚úÖ Evaluate models on test datasets\n",
        "\n",
        "For more information, check the main README.md and model-specific documentation!\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
